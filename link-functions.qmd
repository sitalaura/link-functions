---
title: "Are we getting interactions wrong? <br> The role of link functions <br> in psychological research"
authors: "Laura Sità, Margherita Calderan, Tommaso Feraco, <br> Filippo Gambarota, Enrico Toffalini"
format:
  revealjs:
    center: true
    embed-resources: true
    slide-number: true
    footer: "Cognitive Science Arena 2026"
    # theme: night
    output-file: "link-functions.html"
toc: true
execute:
  cache: false
  freeze: false
include-in-header:
  - text: |
      <style>
      /* Titolo slide di copertina */
      #title-slide .title {
        font-size: 1.5em;
       <!-- color: #900000; --> 
      }

      /* Logo nella copertina */
      #title-slide::after {
        content: "";
        display: block;
        background-image: url("images/logo.png");
        background-repeat: no-repeat;
        background-position: center;
        background-size: contain;
        height: 250px;
        margin-top: 1.5em;
      }

      /* Titoli interni delle slide */
      .reveal h1, .reveal h2, .reveal h3 {
      <!--  color: #900000 !important; -->
      }

      /* Dimensione leggermente minore per h2 */
      .reveal h2 {
        font-size: 1.2em !important;
      }

      /* testo giustificato */
      .reveal p, .reveal li {
        text-align: justify !important;
        text-justify: inter-word;
      }

      /* footer centrato */
       .reveal .slide-footer,
      .reveal .footer,
      .reveal .revealjs-footer {
        position: fixed; left: 0; right: 0; bottom: 10px;
        width: 100%;
        display: flex !important;
        justify-content: center !important;
        align-items: center !important;
        text-align: center !important;
      }
      </style>
---

# 

```{r source}
#| echo: false
#| include: false
source("R/datasim.R")
ts <- 16
tc <- "black"
```

per chi vuole provare a simulare le cose in tempo reale

qr code che manda a questo link https://github.com/sitalaura/link-functions/tree/main/R

oppure scaricare il file a questo percorso `sitalaura.github.io/link-functions/R/datasim.R`

# 1 Example

## Simulated dataset 1

independent variable: age in years (`years`)

dependent variable: (`variabile`)

**aggiungi screenshot dataset**

## Linear model

using the classical linear predictor

```{r ex1fitL}
#| echo: true
#| eval: false
fitL = glm(y~age, data=d)
```

## Linear model

what we dont see it bc its a default parameter but its actually hidden in our code:

```{r fitL-link}
#| echo: true
#| eval: false
#| code-fold: true
fitL_explicit = glm(y~age, family=gaussian(link="identity"), data=d)
```

::: fragment
the model uses family gaussian and the identity link function
:::

::: fragment
**link function** in GLMs transforms (re-map) the linear predictor X

to the appropriate range of the response variable Y
:::


# 2 Example

## Simulated dataset 2

independent variable: age in years (`years`)

dependent variable: mistakes in a TRUE/FALSE task (`accuracy`)

**aggiungi screenshot dataset**

## Linear model

using the classical linear predictor

```{r fitL}
#| echo: true
#| eval: false
fitL = glm(accuracy~age, data=d)
```

## Linear model

```{r fitL-plot}
#| echo: true
#| code-fold: true

fitL <- glm(accuracy ~ age, data = d)

effL <- data.frame(
  allEffects(
    fitL,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  coord_cartesian(ylim = c(0, 1)) +
  geom_point(size = 4, alpha = .5, color = "darkblue") +
  geom_ribbon(
    data = effL,
    aes(x = age, ymin = lower, ymax = upper),
    alpha = .3, fill = "darkred", color = NA,
    inherit.aes = FALSE
  ) +
  geom_line(
    data = effL,
    aes(x = age, y = fit),
    size = 2, color = "darkred",
    inherit.aes = FALSE
  ) +
  theme(text = element_text(size = ts, color = "black")) +
  scale_x_continuous(breaks = seq(floor(min(d$age)), ceiling(max(d$age)), .5)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  ylab("accuracy") + xlab("Age (years)")

```

::: fragment
questo modello ci aiuta a predire i dati?
:::

## Linear model

no perché a 11 anni i bambini hanno accuratezza del 110%

GRAFICO

::: fragment
effettivamente succede a 11 anni: posterior model predicion 

GRAFICO A DESTRA DELL'ALTRO 
:::

## ❌ Inappropriate model

IN THE FIRST EXAMPLE an identity link was appropriate bc

-   y (`boh`) spans from -inf to +inf

::: fragment
here an identity link is NOT appropriate bc

-   y (`accuracy`) spans from 0 to 1
:::

::: notes
al pubblico: dobbiamo quindi cambiare modello, perché quello lineare non aiuta a predire nuovi dati CIOE non tiene conto dei bound dei data (0 e 1)
domanda: quindi, che modello facciamo? 
risposta: regressione logistica
:::


## ✅ More appropriate model 

```{r fitLogit}
#| echo: true
#| warning: false

fitLogit = glm(accuracy ~ age, data=d, family=binomial(link="logit"), weights= rep(k, nrow(d)))
```

in this case, `link="logit"` makes sure that `y` spans from 0 and 1

## ✅ More appropriate model 

```{r fitLogit-plot}
#| echo: true
#| code-fold: true
#| warning: false

effLogit <- data.frame(
  allEffects(
    fitLogit,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age"]]
)

p1 <- ggplot(d, aes(x = age, y = accuracy)) +
  coord_cartesian(ylim = c(0, 1)) +
  geom_point(size = 4, alpha = .5, color = "darkblue") +
  geom_ribbon(
    data = effLogit,
    aes(x = age, ymin = lower, ymax = upper),
    alpha = .25, fill = "blue", color = NA,
    inherit.aes = FALSE
  ) +
  geom_line(
    data = effLogit,
    aes(x = age, y = fit),
    linewidth = 2, color = "blue",
    inherit.aes = FALSE
  ) +
  theme(text = element_text(size = ts, color = "black")) +
  scale_x_continuous(breaks = seq(floor(min(d$age)), ceiling(max(d$age)), .5)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  labs(y = "accuracy", x = "Age (years)")

p1


```

## ✅ More appropriate model (blue one)

```{r fitP-plot2}
#| echo: true
#| code-fold: true

p2 <- ggplot(d, aes(x = age, y = accuracy)) +
  coord_cartesian(ylim = c(0, 1)) +
  geom_point(size = 4, alpha = .5, color = "darkblue") +
  geom_ribbon(
    data = effLogit,
    aes(x = age, ymin = lower, ymax = upper),
    alpha = .25, fill = "blue", color = NA,
    inherit.aes = FALSE
  ) +
  geom_line(
    data = effLogit,
    aes(x = age, y = fit),
    linewidth = 2, color = "blue",
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = effL,
    aes(x = age, ymin = lower, ymax = upper),
    alpha = .3, fill = "darkred", color = NA,
    inherit.aes = FALSE
  ) +
  geom_line(
    data = effL,
    aes(x = age, y = fit),
    size = 2, color = "darkred",
    inherit.aes = FALSE
  ) +
  theme(text = element_text(size = ts, color = "black")) +
  scale_x_continuous(
    breaks = seq(floor(min(d$age)), ceiling(max(d$age)), .5)
  ) +
  scale_y_continuous(
    breaks = seq(0, 1, .1)
  ) +
  labs(y = "accuracy", x = "Age (years)")

p1 | p2

```

::: notes
vediamo graficamente che il modello predice bene i dati nuovi
ci permette di predire nuovi outcome compresi tra 0 e 1
:::

# 3 Studying interactions

## Simulated dataset 2

independent variable: age in years (`years`)

dependent variable: mistakes in a TRUE/FALSE task (`accuracy`)

::: fragment
**adding a new main effect**

groups: normal kids (`group = 0`) vs kids with dyslexia (`group = 1`)
:::

## Identity link function

using an linear model `family=gaussian(link="identity")` a positive interaction emerges

```{r fitLint}
#| echo: true
#| include: true
#| warning: true
fitLint = glm(accuracy ~ age*group, data=d)
summary(fitLint)
```

## Identity link function

```{r fitLint-plot}
#| echo: true
#| warning: false
#| code-fold: true

d$group <- as.factor(d$group)

eff_obj <- allEffects(
  fitLint,
  xlevels = list(age = seq(min(d$age), max(d$age), .05))
)[["age:group"]]

effL <- as.data.frame(eff_obj)

if (!("fit" %in% names(effL))) {
  pred_col <- intersect(c("fit", "response", "fitted", "yhat"), names(effL))
  if (length(pred_col) == 0) stop("Nessuna colonna di predizione trovata in effL.")
  effL$fit <- effL[[pred_col[1]]]
}

ggplot(d, aes(x = age, y = accuracy, shape = group, color = group)) +
  geom_point(size = 4, alpha = .6) +
  geom_ribbon(
    data = effL,
    aes(x = age, ymin = lower, ymax = upper, fill = group, group = group),
    alpha = .3,
    color = NA,
    inherit.aes = FALSE
  ) +
  geom_line(
    data = effL,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2,
    inherit.aes = FALSE
  ) +
  scale_color_manual(values = c("darkorange3", "darkgreen")) +
  scale_fill_manual(values = c("darkorange3", "darkgreen")) +
  theme(text = element_text(size = ts, color = tc)) +
  scale_x_continuous(breaks = seq(floor(min(d$age)), ceiling(max(d$age)), .5)) +
  scale_y_continuous(breaks = seq(0, 1, .1), limits = c(0, 1)) +
  labs(y = "Accuracy", x = "Age (years)")


```

## Logit link function

using an linear model `family=binomial(link="logit")` a negative interaction emerges

```{r fitLogitint}
#| echo: true
#| include: true
#| warning: false

fitLogitint = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"),
          weights= rep(k, nrow(d)))
summary(fitLogitint)
```

## Logit link function

```{r fitLogitint-plot}
#| echo: true
#| code-fold: true
#| eval: false

fitLogitint <- glm(
  accuracy ~ age * group,
  data = d,
  family = binomial(link = "logit"),
  weights = rep(k, nrow(d))
)

effP <- data.frame(
  allEffects(
    fitLogitint,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

effP$group <- as.factor(effP$group)

ggplot(d, aes(x = age, y = accuracy, shape = group, color = group)) +
  geom_point(size = 4, alpha = .6) +
  geom_ribbon(
    data = effP,
    aes(x = age, ymin = lower, ymax = upper, group = group, fill = group),
    alpha = .3, color = NA,
    inherit.aes = FALSE
  ) +
  geom_line(
    data = effP,
    aes(x = age, y = fit, group = group, linetype = group, color = group),
    linewidth = 2,
    inherit.aes = FALSE
  ) +
  scale_color_manual(values = c("darkorange2", "darkgreen")) +
  scale_fill_manual(values = c("darkorange2", "darkgreen")) +
  theme(text = element_text(size = ts, color = "black")) +
  scale_x_continuous(breaks = seq(floor(min(d$age)), ceiling(max(d$age)), .5)) +
  scale_y_continuous(breaks = seq(0, 1, .1), limits = c(0, 1)) +
  ylab("accuracy") + xlab("Age (years)")

```

::: notes
domanda (per alzata di mano): quale dei due modelli riflette ciò che ho simulato? o nessuno dei due?
riformula la domanda: in termini dell'esempio tipo all'aumentare dell'età,... 
e perché?
:::

## cosa ho effettivamente simulato

```{r datasim}
#| echo: true
#| include: true
#| code-folder: true

#codice della simulazione 
```

non ho simulato un'interazione, quindi ENTRAMBI i modelli trovano un'interazione che non c'è.

::: notes
sappiamo perché il modello lineare non funziona (da prima). ma perché non anche il modello di regressione logistica?
risposta: perché se tiro TUTTO a caso in un compito vero/falso di cui non si sa nulla del contenuto, allora l'accuratezza è del 50% non 0%! la regrssione logistica invece dice proprio questo: accuratezza dello 0%
pertanto, anche se la family è giusta (perché ci permette di predire sempre valori che spannano tra 0 e 1), dobbiamo usare un link diverso, che tenga conto di sta cosa. 
il link in questione si chiama e ve lo mostro nel modello
:::

## il vero modello in grado di fittare i dati: link="mafc.probit"

let's try out the multiple alternative forced choice (50% - bc of the true/false) probit link

```{r fitMint1}
#| echo: true
#| eval: false
fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.probit(.m=2)), weights= rep(k, nrow(d)))

```

## il vero modello in grado di fittare i dati: link="mafc.probit"

using an linear model `family=binomial(link="mafc.probit")` no interaction emerges !!!! as it should be

```{r fitMint2}
#| echo: true
#| warning: true

fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.probit(.m=2)), weights= rep(k, nrow(d)))

summary(fitM)
```

# 4 Why interactions

## Identity link function

equal intervals on X correspond to equal intervals on Y

su x ed y metti i nomi delle variabili dell'esempio

```{r idlink}
#| echo: false
#| fig.align: "center" 

df_line <- data.frame(
  x = seq(-4.5, 4.5, length.out = 200)
)
df_line$y <- df_line$x


x_vals <- -4:4
y_vals <- -4:4

ggplot(df_line, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "blue",
    linewidth = 2
  ) +
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(-4.5, 4.5),
    breaks = y_vals
  ) +
  
  # Etichette
  labs(
    x = "Linear component of the model",
    y = "Dependent variable"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14)
  )
```

## ✅ Log link function

equal intervals on X correspond to equal ratios (NOT equal intervals) on Y

```{r loglink}
#| echo: false
#| warning: false
#| fig.align: "center" 

df <- data.frame(
  x = seq(-2.2, 1.6, length.out = 300)
)
df$y <- exp(df$x)

x_vals <- seq(-1.5, 1.5, by = 0.5)
y_vals <- exp(x_vals)

ggplot(df, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "blue",
    linewidth = 2
  ) +
  annotate(
    "text",
    x = -2.25,
    y = y_vals,
    label = paste("y =", round(y_vals, 2)),
    hjust = 1,
    size = 4
  ) +
  annotate(
    "text",
    x = x_vals,
    y = -0.08,
    label = paste("x =", x_vals),
    vjust = 1,
    size = 4
  ) +
  scale_x_continuous(
    limits = c(-2.2, 1.6),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(0, max(y_vals) + 0.8),
    breaks = y_vals
  ) +
  labs(
    x = "Linear component of the model",
    y = "Dependent variable (ie error rate)"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14)
  )
```


# Conclusions

## 

Building a model means that we want to find the processo generativo dei dati which, diversamente dal mondo delle simulazioni, we could never know for sure

to do that we must make important decisions

choosing the more appropriate **family of distributions** to make sure that the new values of the vd im predicting lie within the bounds

choosing the more appropriate **link function**: otherwise it's very likely you end up finding non linear effects (ie interactions) that are not there!

##

We're conducting a [systematic review](https://osf.io/tpjax/overview?view_only=7feccf54ff484fe093cf65579617b215) concerning how often the wrong link functions are used in psychological research + they lead to finding a significant interaction: so far, quite often

## Materials & Contact

All materials are available on GitHub at <a href="https://github.com/sitalaura/link-functions.git" target="_blank">sitalaura/link-functions</a>

Questions and feedbacks <a href="mailto: laura.sita@studenti.unipd.it" target="_blank">laura.sita\@studenti.unipd.it</a>

![](images/logo.png){fig-align="center" width="2.4cm"}

## Bibliography

<p style="font-size:70%; text-align:left; line-height:1.2;">
Domingue, B. W., Kanopka, K., Trejo, S., Rhemtulla, M., & Tucker-Drob, E. M. (2024). Ubiquitous bias and false discovery due to model misspecification in analysis of statistical interactions: The role of the outcome’s distribution and metric properties. *Psychological methods, 29*(6), 1164.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2;">
Hardwicke, T. E., Thibault, R. T., Clarke, B., Moodie, N., Crüwell, S., Schiavone, S. R., Handcock, S. A., Nghiem, K. A., Mody, F., Eerola, T., et al. (2024). Prevalence of transparent research practices in psychology: A cross-sectional study of empirical articles published in 2022. *Advances in Methods and Practices in Psychological Science, 7* (4), 25152459241283477.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2;">
Liddell, T. M., & Kruschke, J. K. (2018). Analyzing ordinal data with metric models: What could possibly go wrong?. *Journal of Experimental Social Psychology, 79*, 328-348.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2;">
Micceri, T. (1989). The unicorn, the normal curve, and other improbable creatures. *Psychological bulletin, 105*(1), 156.
</p>

## Thank you

Special thanks to

# Supplementary materials

## Probit link function 

```{r fitPint}
#| echo: true

fitPint = glm(accuracy ~ age*group, data=d, family=binomial(link="probit"),
          weights= rep(k, nrow(d)))
summary(fitPint)
```