---
title: "Are we getting interactions wrong? <br> The role of link functions <br> in psychological research"
authors: "Laura Sità, Margherita Calderan, Tommaso Feraco, <br> Filippo Gambarota, Enrico Toffalini"
subtitle: |
  <div style="
    display:flex;
    justify-content:center;
    align-items:center;
    margin: 1.4em 0 1.2em 0;
  ">
    <img src="images/logo.png" style="height:155px; margin-right:3cm;">
    <img src="images/logo-UNIPD.bmp" style="height:150px;">
  </div>
format:
  revealjs:
    theme: custom.scss
    center: true
    embed-resources: true
    slide-number: true
    footer: "Cognitive Science Arena 2026"
    output-file: "link-functions.html"
    controls: false
toc: false
execute:
  cache: false
  freeze: false
---

```{r source}
#| echo: false
#| include: false
#source("R/datasim.R")

library(ggplot2)
library(effects)
library(psyphy)
library(ggnewscale)

ts <- 16
tc <- "black"
```

## Simulated dataset

- 1,000 subjects
  - 500 typically developing children (`group = 0`)
  - 500 children with dyslexia (`group = 1`)
- 50 trials per participant

::: fragment
- Independent variable 1: **<span style="color:#800000;">age</span>** (in years)
- Independent variable 2: **<span style="color:#800000;">group</span>**
- Dependent variable: **<span style="color:#800000;">accuracy</span>** in a TRUE/FALSE task
:::

## Simulated dataset

```{r datasim1}
#| echo: false
#| fig.align: center

set.seed(0)

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k

d = data.frame(
  age = age,
  age_c = age - mean(age),
  accuracy = accuracy,
  group = as.factor(group)
)

pal_points <- c("0" = "#7F97E8", "1" = "#ed8f58")
pal_lines  <- c("0" = "#4E6BDC", "1" = "#ff911c")

pal_predcheck <- c(
  observed  = "#222222",
  predicted = "#a68efa",
  model     = "#cf3e65"
)

theme_pres <- theme_minimal(base_size = 22) +
  theme(
    axis.title.x = element_text(size = 26, margin = margin(t = 10)),
    axis.title.y = element_text(size = 26, margin = margin(r = 16)),
    axis.text    = element_text(size = 22),
    legend.title = element_text(size = 24),
    legend.text  = element_text(size = 22),
    plot.title   = element_text(size = 28),
    strip.text   = element_text(size = 22),
    panel.background = element_rect(fill = "grey92", color = NA),
    plot.background  = element_rect(fill = "white", color = NA),
    panel.grid.major = element_line(color = "white", linewidth = 0.6),
    panel.grid.minor = element_line(color = "white", linewidth = 0.3)
  )

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point(size = 1.3, alpha = 0.6) +
  scale_x_continuous(limits = c(6, 10), breaks = seq(6, 10, 1)) +
  scale_color_manual(values = pal_points) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```
## Building the model

Key choices:

- **<span style="color:#800000;">family</span>**
  <br> specifies the response distribution and its valid range 
  <br> (e.g., unbounded, $[0,1]$, counts)

- **<span style="color:#800000;">link function</span>**
  <br> maps the linear predictor  $\beta_0 + \beta_1 \cdot age + \beta_2 \cdot group$  
  onto the scale of the response variable $Y$

::: notes
specifica che la scelta della link dipendende dalla family
:::

# Linear model

## `family=gaussian(link="identity")`

```{r fitL-plot}
#| echo: false
#| warning: false
#| fig.align: center

fitLint <- glm(accuracy ~ age * group, family=gaussian(link="identity"), data = d)

eff <- data.frame(
  allEffects(
    fitLint,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
c'è un'interazione
però mi chiedo.. questo modello ci aiuta a predire i dati? per rispondere alla domanda usiamo questo trick: usiamo il modello costruito per creare un nuovo dataset These are one simulated dataset generated from the fitted model. se il nuovo dataset somiglia ai dati che già possediamo, allora la risposta è "si, il modello ci aiuta a predire nuovi dati". se invece il dataset nuovo, che apparirà sotto forma di puntini viola (i nuovi dati) è diverso dal precedente, allora "no, il modello che ho costruito non predice bene nuovi dati, a partire da quelli di cui dispongo (simulati, come in questo caso, o osservati)"
:::

## Predictive check

<span style="color:#a68efa;">New predicted values</span> fall outside the valid range for accuracy [0,1]

```{r fitL-plot-pred}
#| echo: false
#| fig.align: center

d$pp_sim <- simulate(fitLint)$sim_1

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(
    aes(y = pp_sim),
    color = pal_predcheck["predicted"],
    size = 2.5,
    alpha = 0.4
  ) +
  geom_point(
    color = pal_predcheck["observed"],
    size = 1.3,
    alpha = 0.6
  ) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    color = pal_predcheck["model"],
    linewidth = 2
  ) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
il modello predice dati fuori dal range dei valori possibili
per curiosità, andiamo comunque a vedere il summary del modello
:::

## `family=gaussian(link="identity")`

A **positive** interaction emerges

```{r fitLsum}
#| echo: true
#| include: true
#| warning: true
fit = glm(accuracy ~ age*group, family=gaussian(link="identity"), data=d)
summary(fit)
```

::: notes
CHIEDI: quindi che modello possiamo fare?
:::

# Logistic regression model

## `family=binomial(link="logit")`

```{r fitLogit-plot}
#| echo: false
#| warning: false
#| fig.align: center

fitLogit = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"),
          weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitLogit,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
c'è un'interazione
questo modello non sembra avere problemi
:::

## Predictive check

<span style="color:#a68efa;">New predicted values</span> fall within the valid range for accuracy [0,1]

```{r fitLogit-pred}
#| echo: false
#| fig.align: center

p_hat <- fitted(fitLogit)                      
d$pp_sim <- rbinom(nrow(d), size = k, prob = p_hat) / k

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(
    aes(y = pp_sim),
    color = pal_predcheck["predicted"],
    size = 2.5,
    alpha = 0.4
  ) +
  geom_point(
    color = pal_predcheck["observed"],
    size = 1.3,
    alpha = 0.6
  ) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    color = pal_predcheck["model"],
    linewidth = 2
  ) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
ovvero predice dati all'interno dal range dei valori possibili
anche qui andiamo a vedere il summary del modello
:::

## `family=binomial(link="logit")`

A **negative** interaction emerges

```{r fitLogitsum}
#| echo: true
#| include: true
#| warning: false

fit = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"), weights= rep(k, nrow(d)))
summary(fit)
```

::: notes
domanda (per alzata di mano): quale dei due modelli riflette ciò che ho simulato? o nessuno dei due? ---E IMPORTANTE--- riformula la domanda: in termini dell'esempio tipo all'aumentare dell'età,... e perché? ho già dato un hint dicendo che il primo modello in realtà ha un problema.. 
:::

# The appropriate model

## What was actually simulated

```{r datasim2}
#| echo: true
#| code-fold: true
#| fig.align: center

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k

d = data.frame(
  age = age,
  age_c = age - mean(age),
  accuracy = accuracy,
  group = as.factor(group))
```

```{r datasim3}
#| echo: false
#| fig.align: center

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```

::: fragment
No interaction was simulated

<span style="color:#800000;"> Both models are detecting **an interaction that does not exist** </span>
:::

::: notes
sappiamo perché il modello lineare non funziona (da prima). ma perché non anche il modello di regressione logistica? risposta: perché se tiro TUTTO a caso in un compito vero/falso di cui non si sa nulla del contenuto, allora l'accuratezza è del 50% non 0%! la regrssione logistica invece dice proprio questo: accuratezza dello 0% pertanto, anche se la family è giusta (perché ci permette di predire sempre valori che spannano tra 0 e 1), dobbiamo usare un link diverso, che tenga conto di sta cosa. il link in questione si chiama e ve lo mostro nel modello
:::

## `family=binomial(link=mafc.probit(.m=2)`

To account for the 50\% chance level in a TRUE/FALSE task:

**<span style="color:#800000;">2 alternatives forced-choice probit link</span>**

```{r fitMint-plot}
#| echo: false
#| warning: false
#| fig.align: center

fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.probit(.m=2)), weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitM,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```

## `family=binomial(link=mafc.probit(.m=2)`

No interaction emerges, in line with how the data were generated

```{r fitMint}
#| echo: true
#| warning: true

fit = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.probit(.m=2)), weights= rep(k, nrow(d)))
summary(fit)
```

# Why interactions

::: notes
noi testiamo di solito effetti lineari (quasi mai non lineari), mentre le interazioni le vai a vedere quasi sempre (i software tipo spss li mostrano) ed è un tipo di non linearità che viene testato quasi non intenzionalmente. pertanto il ricercatore testa effetti non lineari (interazioni) col link sbagliato (risentendo del problema delle trasformazioni di differenze) 
:::

## `link="identity"`

Equal intervals on X correspond to equal intervals on Y

```{r idlink}
#| echo: false
#| fig.align: "center" 

df_line <- data.frame(
  x = seq(-4.5, 4.5, length.out = 200)
)
df_line$y <- df_line$x


x_vals <- -4:4
y_vals <- -4:4

ggplot(df_line, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "#4E6BDC",
    linewidth = 2
  ) +
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(-4.5, 4.5),
    breaks = y_vals
  ) +

  labs(
    x = "Linear predictor",
    y = "Continuous outcome"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title.x = element_text(size = 22, margin = margin(t = 10)),
    axis.title.y = element_text(size = 22, margin = margin(r = 16)),
    axis.text = element_text(size = 14)
  )
```

In our example the linear predictor is $\beta_0 + \beta_1 \cdot age + \beta_2 \cdot group$

## `link="logit"`

Equal intervals on X correspond to equal ratios (NOT equal intervals) on Y

```{r loglink}
#| echo: false
#| warning: false
#| fig.align: "center" 

df_line <- data.frame(
  x = seq(-5, 5, length.out = 400)
)
df_line$y <- plogis(df_line$x)

x_vals <- -4:4
y_vals <- plogis(x_vals)

ggplot(df_line, aes(x = x, y = y)) +

  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "#4E6BDC",
    linewidth = 2
  ) +
  
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  
  scale_y_continuous(
    limits = c(0, 1),
    breaks = round(y_vals, 2),
    labels = round(y_vals, 2)
  ) +
  
  labs(
    x = "Linear predictor",
    y = "Accuracy"
  ) +
  
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title.x = element_text(size = 22, margin = margin(t = 10)),
    axis.title.y = element_text(size = 22, margin = margin(r = 16)),
    axis.text = element_text(size = 15)
  )

```

## `link=mafc.probit(2)`

Equal intervals on X do NOT correspond to equal intervals on Y

```{r macflink}
#| echo: false
#| warning: false
#| fig.align: "center" 

mafc_probit_linkinv <- function(x, m) {
  g <- 1 / m
  g + (1 - g) * pnorm(x)
}

df_line <- data.frame(x = seq(-4.5, 4.5, length.out = 400))
df_line$y <- mafc_probit_linkinv(df_line$x, m = 2)

x_vals <- -4:4
y_vals <- mafc_probit_linkinv(x_vals, m = 2)

y_breaks <- mafc_probit_linkinv(c(-4, -1, 0, 1, 2, 3, 4), m = 2)
y_breaks <- round(y_breaks, 2)

y_breaks <- y_breaks[y_breaks < 1]
y_breaks <- c(y_breaks, 0.99)

ggplot(df_line, aes(x = x, y = y)) +
  geom_hline(yintercept = y_vals, color = "grey60", linewidth = 0.6) +
  geom_vline(xintercept = x_vals, color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_line(color = "#4E6BDC", linewidth = 2) +
  geom_hline(yintercept = 1/2, linewidth = 1) +
  scale_x_continuous(limits = c(-4.5, 4.5), breaks = x_vals) +
  scale_y_continuous(
    limits = c(0.25, 1),
    breaks = y_breaks,
    labels = y_breaks
  ) +
  labs(x = "Linear predictor", y = "Accuracy") +
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title.x = element_text(size = 22, margin = margin(t = 10)),
    axis.title.y = element_text(size = 22, margin = margin(r = 16)),
    axis.text = element_text(size = 15)
  )

```

# Conclusions

##

Building a model means approximating the data-generating process (never observed directly in real data)

Key choices:

::: {.callout-tip}
**Appropriate distribution (family):**
<br> predicted values remain within the outcome’s valid range
:::

::: {.callout-tip}
**Appropriate link function: **  
the wrong link can create spurious interactions
:::

## Our [systematic review](https://osf.io/tpjax/overview?view_only=7feccf54ff484fe093cf65579617b215) of psychological research

How often 

- inappropriate link functions are used when testing interactions?

- do they lead to significant results?

## Materials & Contact

Data simulation, code and presentation are available on GitHub: <a href="https://github.com/sitalaura/link-functions.git" target="_blank">sitalaura/link-functions</a>

Questions and feedbacks: <a href="mailto: laura.sita@studenti.unipd.it" target="_blank">laura.sita\@studenti.unipd.it</a>

<div style="margin-top:3em;"></div>

::::: columns
::: {.column width="45%"}
![](images/logo.png){fig-align="center" width="160"}
:::

::: {.column width="55%"}
![](images/logo-UNIPD.bmp){fig-align="left" width="400"}
:::
:::::

## Bibliography

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Domingue, B. W., Kanopka, K., Trejo, S., Rhemtulla, M., & Tucker-Drob, E. M. (2024). Ubiquitous bias and false discovery due to model misspecification in analysis of statistical interactions: The role of the outcome’s distribution and metric properties. *Psychological methods, 29*(6), 1164.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Hardwicke, T. E., Thibault, R. T., Clarke, B., Moodie, N., Crüwell, S., Schiavone, S. R., Handcock, S. A., Nghiem, K. A., Mody, F., Eerola, T., et al. (2024). Prevalence of transparent research practices in psychology: A cross-sectional study of empirical articles published in 2022. *Advances in Methods and Practices in Psychological Science, 7* (4), 25152459241283477.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Liddell, T. M., & Kruschke, J. K. (2018). Analyzing ordinal data with metric models: What could possibly go wrong?. *Journal of Experimental Social Psychology, 79*, 328-348.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Micceri, T. (1989). The unicorn, the normal curve, and other improbable creatures. *Psychological bulletin, 105*(1), 156.
</p>

# Supplementary materials

## Predictive check with `link="probit"`

```{r sup1}
#| echo: false
#| warning: false
#| fig.align: center

fitProbit = glm(accuracy ~ age*group, data=d, family=binomial(link="probit"),
          weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitProbit,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)
```

```{r sup2}
#| echo: false
p_hat <- fitted(fitProbit)                      
d$pp_sim <- rbinom(nrow(d), size = k, prob = p_hat) / k

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(
    aes(y = pp_sim),
    color = pal_predcheck["predicted"],
    size = 3.5,
    alpha = 0.4
  ) +
  geom_point(
    color = pal_predcheck["observed"],
    size = 1.3,
    alpha = 0.6
  ) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    color = pal_predcheck["model"],
    linewidth = 2
  ) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```

## `family=binomial(link="probit")`

A **negative** interaction emerges

```{r sup3}
#| echo: true
#| include: true
#| warning: true

fit = glm(accuracy ~ age*group, data=d, family=binomial(link="probit"), weights= rep(k, nrow(d)))
summary(fit)
```


