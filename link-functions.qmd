---
title: "Are we getting interactions wrong? <br> The role of link functions <br> in psychological research"
authors: "Laura Sità, Margherita Calderan, Tommaso Feraco, <br> Filippo Gambarota, Enrico Toffalini"
subtitle: |
  <div style="
    display:flex;
    justify-content:center;
    align-items:center;
    margin: 1.4em 0 1.2em 0;
  ">
    <img src="images/logo.png" style="height:155px; margin-right:3cm;">
    <img src="images/logo-UNIPD.bmp" style="height:150px;">
  </div>
format:
  revealjs:
    theme: custom.scss
    center: true
    embed-resources: true
    slide-number: true
    footer: "Cognitive Science Arena 2026"
    output-file: "link-functions.html"
    controls: false
toc: false
execute:
  cache: false
  freeze: false
---

```{r setup}
#| echo: false
#| include: false

library(ggplot2)
library(patchwork)
library(effects)
library(psyphy)
library(ggnewscale)
library(filor)

ts <- 16
tc <- "black"

style_output <- function(x, lines, class = "hg"){
  x <- capture.output(x)
  x <- htmltools::htmlEscape(x)
  x[lines] <- sprintf("<span class='%s'>%s</span>", class, x[lines])
  cat("<pre><code>")
  cat(x, sep = "\n")
  cat("</code></pre>")
}

```

## Our dataset

- 1,000 subjects
  - 500 typically developing children (`group = 0`)
  - 500 children with dyslexia (`group = 1`)
- 50 trials per participant

::: fragment
- Independent variable 1: **<span style="color:#800000;">age</span>** (in years)
- Independent variable 2: **<span style="color:#800000;">group</span>**
- Dependent variable: **<span style="color:#800000;">accuracy</span>** in a TRUE/FALSE task
:::

::: fragment
![](images/hand.jpg){.absolute bottom=90 right=0 width="360" height="220"}
:::

## Our dataset

```{r datasim1}
#| echo: false
#| fig.align: center

set.seed(123) 

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group # simulated linear predictor
probs = mafc.logit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k

d = data.frame(
  age = age,
  age_c = age - mean(age),
  accuracy = accuracy,
  group = as.factor(group)
)

pal_points <- c("0" = "#7F97E8", "1" = "#ed8f58")
pal_lines  <- c("0" = "#4E6BDC", "1" = "#fa6b0c")

pal_predcheck <- c(
  observed  = "#222222",
  predicted = "#a68efa",
  model     = "#cf3e65"
)

theme_pres <- theme_minimal(base_size = 22) +
  theme(
    axis.title.x = element_text(size = 26, margin = margin(t = 10)),
    axis.title.y = element_text(size = 26, margin = margin(r = 16)),
    axis.text    = element_text(size = 22),
    legend.title = element_text(size = 24),
    legend.text  = element_text(size = 22),
    plot.title   = element_text(size = 28),
    strip.text   = element_text(size = 22),
    panel.background = element_rect(fill = "grey92", color = NA),
    plot.background  = element_rect(fill = "white", color = NA),
    panel.grid.major = element_line(color = "white", linewidth = 0.6),
    panel.grid.minor = element_line(color = "white", linewidth = 0.3)
  )

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point(size = 1.3, alpha = 0.6) +
  scale_x_continuous(limits = c(6, 10), breaks = seq(6, 10, 1)) +
  scale_color_manual(values = pal_points) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```

::: notes
ogni puntino = un bambino
asse x: età 
asse y: quante risposte corrette dà / 50 domande vero-falso
:::

## Building the model

Key choices:

- **<span style="color:#800000;">family</span>**
  <br> specifies the response distribution and its valid range 
  <br> (e.g., unbounded, $[0,1]$, counts)

- **<span style="color:#800000;">link function</span>**
  <br> maps the linear predictor  $\beta_0 + \beta_1 \cdot age + \beta_2 \cdot group$  
  onto the scale of the response variable $Y$

::: notes
specifica che la scelta della link dipendende dalla family

andiamo a vedere con un linear model (lm), quello che tutti facciamo sempre
:::

# Linear model

## `family=gaussian(link="identity")`

```{r fitL-plot}
#| echo: false
#| warning: false
#| fig.align: center

fitLint <- glm(accuracy ~ age * group, family=gaussian(link="identity"), data = d)

eff <- data.frame(
  allEffects(
    fitLint,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
c'è un'interazione
però mi chiedo.. questo modello ci aiuta a predire i dati? per rispondere alla domanda usiamo questo trick: usiamo il modello costruito per creare un nuovo dataset These are one simulated dataset generated from the fitted model. se il nuovo dataset somiglia ai dati che già possediamo, allora la risposta è "si, il modello ci aiuta a predire nuovi dati". se invece il dataset nuovo, che apparirà sotto forma di puntini viola (i nuovi dati) è diverso dal precedente, allora "no, il modello che ho costruito non predice bene nuovi dati, a partire da quelli di cui dispongo (simulati, come in questo caso, o osservati)"

prende il modello come se fosse la vera data-generating process
e simula cosa potresti osservare se rifacessi l’esperimento.
:::

## Predictive check

<span style="color:#a68efa;">New predicted values</span> fall outside the valid range for accuracy [0,1]

```{r fitL-plot-pred}
#| echo: false
#| fig.align: center

d$pp_sim <- simulate(fitLint)$sim_1

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(
    aes(y = pp_sim),
    color = pal_predcheck["predicted"],
    size = 2.5,
    alpha = 0.4
  ) +
  geom_point(
    color = pal_predcheck["observed"],
    size = 1.3,
    alpha = 0.6
  ) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    color = pal_predcheck["model"],
    linewidth = 2
  ) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
il modello predice dati fuori dal range dei valori possibili
per curiosità, andiamo comunque a vedere il summary del modello
:::

## `family=gaussian(link="identity")`

A **positive** interaction emerges

```{r fitLsum}
#| eval: false
#| echo: true
#| warning: true
fit = glm(accuracy ~ age*group, family=gaussian(link="identity"), data=d)
summary(fit)
```

```{r fitLsum2}
#| echo: false
#| warning: true
#| message: false
#| output: asis

fit <- glm(accuracy ~ age*group, family = gaussian(link="identity"), data = d)

ss <- capture.output(summary(fit))
ss <- ss[5:11]
hl <- grep("age:group", ss)
style_output(cat(ss, sep = "\n"), lines = hl, class = "hg")

```

::: notes
CHIEDI: quindi che modello possiamo fare?
:::

# Logistic regression model

## `family=binomial(link="logit")`

```{r fitLogit-plot}
#| echo: false
#| warning: false
#| fig.align: center

fitLogit = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"),
          weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitLogit,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres 

```

## Predictive check

<span style="color:#a68efa;">New predicted values</span> fall within the valid range for accuracy [0,1]

```{r fitLogit-pred}
#| echo: false
#| fig.align: center

p_hat <- fitted(fitLogit)                      
d$pp_sim <- rbinom(nrow(d), size = k, prob = p_hat) / k

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(
    aes(y = pp_sim),
    color = pal_predcheck["predicted"],
    size = 2.5,
    alpha = 0.4
  ) +
  geom_point(
    color = pal_predcheck["observed"],
    size = 1.3,
    alpha = 0.6
  ) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    color = pal_predcheck["model"],
    linewidth = 2
  ) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres

```

::: notes
ovvero predice dati all'interno dal range dei valori possibili
anche qui andiamo a vedere il summary del modello
:::

## `family=binomial(link="logit")`

```{r fitLogit-plot2}
#| echo: false
#| warning: false
#| fig.align: center

fitLogit <- glm(
  accuracy ~ age * group,
  data = d,
  family = binomial(link = "logit"),
  weights = rep(k, nrow(d))
)

eff <- data.frame(
  allEffects(
    fitLogit,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

p_left <- ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2
  ) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres +
  theme(legend.position = "none")

p_right <- ggplot(d, aes(x = age, y = qlogis(accuracy - 0.001))) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = qlogis(fit), color = group, group = group),
    linewidth = 2
  ) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Logit(accuracy)") +
  theme_pres

p_left | p_right

```

::: notes
c'è un'interazione
questo modello non sembra avere problemi
:::

## `family=binomial(link="logit")`

A **negative** interaction emerges

```{r fitLogitsum}
#| eval: false
#| echo: true
#| warning: true

fit = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"), weights= rep(k, nrow(d)))
summary(fit)
```

```{r fitLogitsum2}
#| echo: false
#| warning: true
#| output: asis

fit = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"), weights= rep(k, nrow(d)))

ss <- capture.output(summary(fit))
ss <- ss[5:11]
hl <- grep("age:group", ss)
style_output(cat(ss, sep = "\n"), lines = hl, class = "hg")
```

::: notes
domanda (per alzata di mano): quale dei due modelli riflette ciò che ho simulato? o nessuno dei due? ---E IMPORTANTE--- riformula la domanda: in termini dell'esempio tipo all'aumentare dell'età,... e perché? ho già dato un hint dicendo che il primo modello in realtà ha un problema.. 
:::

# The appropriate model

## The dataset...

```{r datasim3}
#| echo: false
#| fig.align: center

d = data.frame(
  age = age,
  age_c = age - mean(age),
  accuracy = accuracy,
  group = as.factor(group))

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point(size = 1.3, alpha = 0.6) +
  scale_x_continuous(limits = c(6, 10), breaks = seq(6, 10, 1)) +
  scale_color_manual(values = pal_points) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```

## ... was actually simulated

```{r datasim22}
#| echo: true
#| eval: false
#| fig.align: center
#| code-line-numbers: "|7|"

set.seed(123)

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group  # linear predictor
probs = mafc.logit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k
```

No interaction was simulated

<span style="color:#800000;"> Both models are detecting **an interaction that does not exist** </span>

::: notes
sappiamo perché il modello lineare non funziona (da prima). ma perché non anche il modello di regressione logistica? risposta: perché se tiro TUTTO a caso in un compito vero/falso di cui non si sa nulla del contenuto, allora l'accuratezza è del 50% non 0%! la regrssione logistica invece dice proprio questo: accuratezza dello 0% pertanto, anche se la family è giusta (perché ci permette di predire sempre valori che spannano tra 0 e 1), dobbiamo usare un link diverso, che tenga conto di sta cosa. il link in questione si chiama e ve lo mostro nel modello
:::

## `family=binomial(link=mafc.logit(.m=2))`

To account for the 50\% chance level in a TRUE/FALSE task:

**<span style="color:#800000;">2 alternatives forced-choice logit link</span>**

```{r fitMint-plot}
#| echo: false
#| warning: false
#| fig.align: center

fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.logit(.m=2)), weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitM,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres
```

::: fragment
![](images/hand.jpg){.absolute bottom=60 right=0 width="360" height="220"}
:::

::: notes
se uno fa il task da blind, allora la sua accuratezza è 0.5 LOWER LIMIT DELL’ACCURACY E’ 0.5 E NON 0
:::

## `family=binomial(link=mafc.logit(.m=2))`

```{r fitMint-plot2}
#| echo: false
#| fig.align: center

fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.logit(.m=2)), weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitM,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

p_left <- ggplot(d, aes(x = age, y = accuracy)) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fit, color = group, group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Accuracy") +
  theme_pres +
  theme(legend.position = "none")


fam <- binomial(link = mafc.logit(2))

p_right <- ggplot(d,
  aes(x = age, y = fam$linkfun(pmin(pmax(accuracy, 0.501), 0.999)))) +
  geom_point(aes(color = group), size = 1.6, alpha = 0.45) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fam$linkfun(pmin(pmax(fit, 0.501), 0.999)),
      color = group,
      group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  coord_cartesian(ylim = c(-6, 6)) +
  xlab("Age") +
  ylab("Logit(accuracy)*") +
  theme_pres

p_left | p_right

```

<div style="text-align:right; font-size:0.55em">
  \* Logit(accuracy) with 0.5 as lower bound
</div>


## `family=binomial(link=mafc.logit(.m=2))`

No interaction emerges, in line with how the data were generated

```{r fitMint}
#| eval: false
#| echo: true
#| warning: true

fit = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.logit(.m=2)), weights= rep(k, nrow(d)))
summary(fit)
```

```{r fitMint2}
#| echo: false
#| warning: true
#| output: asis

fit = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.logit(.m=2)), weights= rep(k, nrow(d)))

ss <- capture.output(summary(fit))
ss <- ss[5:11]
hl <- grep("age:group", ss)
style_output(cat(ss, sep = "\n"), lines = hl, class = "hg")

```


# Why interactions

::: notes
noi testiamo di solito effetti lineari (quasi mai non lineari), mentre le interazioni le vai a vedere quasi sempre (i software tipo spss li mostrano) ed è un tipo di non linearità che viene testato quasi non intenzionalmente. pertanto il ricercatore testa effetti non lineari (interazioni) col link sbagliato (risentendo del problema delle trasformazioni di differenze) 
:::

## `link="identity"`

Equal intervals on X correspond to equal intervals on Y

```{r idlink}
#| echo: false
#| fig.align: "center" 

df_line <- data.frame(
  x = seq(-4.5, 4.5, length.out = 200)
)
df_line$y <- df_line$x


x_vals <- -4:4
y_vals <- -4:4

ggplot(df_line, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "#4E6BDC",
    linewidth = 2
  ) +
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(-4.5, 4.5),
    breaks = y_vals
  ) +

  labs(
    x = "Linear predictor",
    y = "Continuous outcome"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title.x = element_text(size = 22, margin = margin(t = 10)),
    axis.title.y = element_text(size = 22, margin = margin(r = 16)),
    axis.text = element_text(size = 14)
  )
```

In our example the linear predictor is $\beta_0 + \beta_1 \cdot age + \beta_2 \cdot group$

## `link="logit"`

Equal intervals on X correspond to equal intervals on Y **when on the logit scale**

```{r loglink}
#| echo: false
#| warning: false
#| fig.align: "center" 

df_line <- data.frame(
  x = seq(-5, 5, length.out = 400)
)
df_line$y <- plogis(df_line$x)

x_vals <- -4:4
y_vals <- plogis(x_vals)

ggplot(df_line, aes(x = x, y = y)) +

  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "#4E6BDC",
    linewidth = 2
  ) +
  
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  
  scale_y_continuous(
    limits = c(0, 1),
    breaks = round(y_vals, 2),
    labels = round(y_vals, 2)
  ) +
  
  labs(
    x = "Linear predictor",
    y = "Accuracy"
  ) +
  
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title.x = element_text(size = 22, margin = margin(t = 10)),
    axis.title.y = element_text(size = 22, margin = margin(r = 16)),
    axis.text = element_text(size = 15)
  )

```

## `link=mafc.logit(2)`

Logit on [*chance level*, 1] instead of [0,1]

```{r macflink}
#| echo: false
#| warning: false
#| fig.align: "center" 

mafc_logit_linkinv <- function(x, m) {
  g <- 1 / m
  g + (1 - g) * plogis(x)
}

df_line <- data.frame(
  x = seq(-5, 5, length.out = 400)
)
df_line$y <- mafc_logit_linkinv(df_line$x, m = 2)

x_vals <- -4:4
y_vals <- mafc_logit_linkinv(x_vals, m = 2)

ggplot(df_line, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "#4E6BDC",
    linewidth = 2
  ) +
  geom_hline(
    yintercept = 1 / 2,
    linewidth = 1
  ) +
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = c(0, 0.25, 0.5, 0.6, 0.75, 0.9, 1),
    labels = c("0.00", "0.25", "0.50", "0.60", "0.75", "0.90", "1.00")
  ) +
  labs(
    x = "Linear predictor",
    y = "Accuracy"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title.x = element_text(size = 22, margin = margin(t = 10)),
    axis.title.y = element_text(size = 22, margin = margin(r = 16)),
    axis.text = element_text(size = 15)
  )

```

::: fragment
![](images/hand.jpg){.absolute bottom=80 right=0 width="360" height="220"}
:::

# Conclusions

##

Building a model means approximating the data-generating process (never observed directly in real data)

Key choices:

::: {.callout-tip title="Family"}
Predicted values remain within the outcome’s valid range
:::

::: {.callout-tip title="Link function"}
Different links change the outcome scale in different ways $\to$ estimated interactions change too

Wrong links can create spurious interactions
:::

## Our [systematic review](https://osf.io/tpjax/overview?view_only=7feccf54ff484fe093cf65579617b215) of psychological research

How often 

- inappropriate link functions are used when testing interactions?

- do they lead to significant results?

::: notes
accennare a suggerimenti per scelta link nel nostro lavoro 
:::

## Materials & Contact

Data simulation, code and presentation are available on GitHub: <a href="https://github.com/sitalaura/link-functions.git" target="_blank">sitalaura/link-functions</a>

Questions and feedbacks: <a href="mailto: laura.sita@studenti.unipd.it" target="_blank">laura.sita\@studenti.unipd.it</a>

<div style="margin-top:3em;"></div>

::::: columns
::: {.column width="45%"}
![](images/logo.png){fig-align="center" width="160"}
:::

::: {.column width="55%"}
![](images/logo-UNIPD.bmp){fig-align="left" width="400"}
:::
:::::

## Bibliography

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Domingue, B. W., Kanopka, K., Trejo, S., Rhemtulla, M., & Tucker-Drob, E. M. (2024). Ubiquitous bias and false discovery due to model misspecification in analysis of statistical interactions: The role of the outcome’s distribution and metric properties. *Psychological methods, 29*(6), 1164.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Hardwicke, T. E., Thibault, R. T., Clarke, B., Moodie, N., Crüwell, S., Schiavone, S. R., Handcock, S. A., Nghiem, K. A., Mody, F., Eerola, T., et al. (2024). Prevalence of transparent research practices in psychology: A cross-sectional study of empirical articles published in 2022. *Advances in Methods and Practices in Psychological Science, 7* (4), 25152459241283477.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Liddell, T. M., & Kruschke, J. K. (2018). Analyzing ordinal data with metric models: What could possibly go wrong?. *Journal of Experimental Social Psychology, 79*, 328-348.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2; padding-left:1.5em; text-indent:-1.5em;">
Micceri, T. (1989). The unicorn, the normal curve, and other improbable creatures. *Psychological bulletin, 105*(1), 156.
</p>

# Supplementary materials

## Logit(accuracy) with `link=logit` 

```{r fitLogit-plot3}
#| echo: false
#| warning: false
#| fig.align: center

fitLogit <- glm(
  accuracy ~ age * group,
  data = d,
  family = binomial(link = "logit"),
  weights = rep(k, nrow(d))
)

eff <- data.frame(
  allEffects(
    fitLogit,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = qlogis(accuracy - 0.001))) +
  geom_point(aes(color = group), size = 1.3, alpha = 0.6) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = qlogis(fit), color = group, group = group),
    linewidth = 2
  ) +
  scale_color_manual(values = pal_lines) +
  xlab("Age") +
  ylab("Logit(accuracy)") +
  theme_pres

```

## Logit(accuracy) with `link=mafc.logit(.m=2)` 

```{r fitMint-plot22}
#| echo: false
#| fig.align: center

fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.logit(.m=2)), weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitM,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

fam <- binomial(link = mafc.logit(2))

ggplot(d,
  aes(x = age, y = fam$linkfun(pmin(pmax(accuracy, 0.501), 0.999)))) +
  geom_point(aes(color = group), size = 1.6, alpha = 0.45) +
  scale_color_manual(values = pal_points) +
  new_scale_color() +
  geom_line(
    data = eff,
    aes(x = age, y = fam$linkfun(pmin(pmax(fit, 0.501), 0.999)),
      color = group,
      group = group),
    linewidth = 2) +
  scale_color_manual(values = pal_lines) +
  coord_cartesian(ylim = c(-6, 6)) +
  xlab("Age") +
  ylab("Logit(accuracy)*") +
  theme_pres

```

<div style="text-align:right; font-size:0.55em">
  \* Logit(accuracy) with 0.5 as lower bound
</div>
