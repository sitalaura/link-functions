---
title: "Are we getting interactions wrong? <br> The role of link functions <br> in psychological research"
authors: "Laura Sità, Margherita Calderan, Tommaso Feraco, <br> Filippo Gambarota, Enrico Toffalini"
format:
  revealjs:
    center: true
    embed-resources: true
    slide-number: true
    footer: "Cognitive Science Arena 2026"
    # theme: night
    output-file: "link-functions.html"
toc: true
execute:
  cache: false
  freeze: false
include-in-header:
  - text: |
      <style>
      /* Titolo slide di copertina */
      #title-slide .title {
        font-size: 1.5em;
       <!-- color: #900000; --> 
      }

      /* Logo nella copertina */
      #title-slide::after {
        content: "";
        display: block;
        background-image: url("images/logo.png");
        background-repeat: no-repeat;
        background-position: center;
        background-size: contain;
        height: 250px;
        margin-top: 1.5em;
      }

      /* Titoli interni delle slide */
      .reveal h1, .reveal h2, .reveal h3 {
      <!--  color: #900000 !important; -->
      }

      /* Dimensione leggermente minore per h2 */
      .reveal h2 {
        font-size: 1.2em !important;
      }

      /* testo giustificato */
      .reveal p, .reveal li {
        text-align: justify !important;
        text-justify: inter-word;
      }

      /* footer centrato */
       .reveal .slide-footer,
      .reveal .footer,
      .reveal .revealjs-footer {
        position: fixed; left: 0; right: 0; bottom: 10px;
        width: 100%;
        display: flex !important;
        justify-content: center !important;
        align-items: center !important;
        text-align: center !important;
      }
      </style>
---

# 

```{r source}
#| echo: false
#| include: false
#source("R/datasim.R")

library(ggplot2)
library(effects)
library(psyphy)

ts <- 16
tc <- "black"
```

# 1 Example

## Simulated dataset 1

independent variable: age in years (`years`)

dependent variable: (`variabile`)

```{r sim1}
#| echo: false
set.seed(2)

N <- 200
age <- runif(N, 6, 10)
r <- 0.7
age_z <- scale(age)
y <- r * age_z + sqrt(1 - r^2) * rnorm(N)
d <- data.frame(age, y)

ggplot(d,aes(x=age,y=y))+
  geom_point()
```

## Linear model

using the classical linear predictor

```{r ex1fitL}
#| echo: true
#| eval: false
fit = lm(y~age, data=d)
```

## Linear model

what we dont see it bc its a default parameter but its actually hidden in our code:

```{r fitL-link}
#| echo: true
#| eval: false
#| code-fold: true
fit = glm(y~age, family=gaussian(link="identity"), data=d)
```

::: fragment
the model uses family gaussian and the identity link function
:::

::: fragment
**link function** in GLMs transforms (re-map) the linear predictor X

to the appropriate range of the response variable Y
:::


# 2 Example

## Simulated dataset 2

independent variable: age in years (`years`)

dependent variable: mistakes in a TRUE/FALSE task (`accuracy`)

```{r sim2}
#| echo: false

set.seed(0)

k = 60
N = 400
age = runif(N,6,10)
eta = -5.5+age*0.9
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k
d = data.frame(age,accuracy)

ggplot(d,aes(x=age,y=accuracy))+
  geom_point()
```

## Linear model

```{r fitL-plot}
#| echo: false
fit = lm(accuracy ~ age, data=d)
eff = data.frame(allEffects(fit,xlevels=list(age=seq(6,10,.1)))$"age")
eff$accuracy = eff$fit
ggplot(d,aes(x=age,y=accuracy))+
  geom_point()+
  geom_line(data=eff,color="red",size=2)
```

## Linear model

using the classical linear predictor

```{r fitL}
#| echo: true
#| eval: false
fit = lm(accuracy~age, data=d)
```

::: notes
questo modello ci aiuta a predire i dati?
per rispondere alla domanda usiamo questo trick: usiamo il modello costruito per creare un nuovo dataset. se il nuovo dataset somiglia ai dati che già possediamo, allora la risposta è "si, il modello ci aiuta a predire nuovi dati". se invece il dataset nuovo, che apparirà sotto forma di puntini viola (i nuovi dati) è diverso dal precedente, allora "no, il modello che ho costruito non predice bene nuovi dati, a partire da quelli di cui dispongo (simulati, come in questo caso, o osservati)"
:::

## Linear model

i nuovi dati simulati dal modello vanno chiaramente fuori dal range (0,1) di possibili valori per l'accuratezza

```{r fitP-plot2}
#| echo: false

d$pp_sim = simulate(fit)$sim_1

ggplot(d,aes(x=age,y=accuracy))+
  geom_point(aes(x=age,y=pp_sim),color="purple",size=3.5,alpha=.4)+
  geom_point()+
  geom_line(data=eff,color="red",size=2) +
  ylab("accuracy")
```

## ❌ Inappropriate model

IN THE FIRST EXAMPLE an identity link was appropriate bc

-   y (`boh`) spans from -inf to +inf

::: fragment
here an identity link is NOT appropriate bc

-   y (`accuracy`) spans from 0 to 1
:::

::: notes
al pubblico: dobbiamo quindi cambiare modello, perché quello lineare non aiuta a predire nuovi dati CIOE non tiene conto dei bound dei data (0 e 1)
domanda: quindi, che modello facciamo? 
risposta: regressione logistica
:::

## ✅ More appropriate model 

```{r fitLogit-plot}
#| echo: false
#| warning: false

fit = glm(accuracy ~ age, data=d, family=binomial(link="logit"),
          weights= rep(k, nrow(d)))

eff = data.frame(allEffects(fit,xlevels=list(age=seq(6,10,.1)))$"age")
eff$accuracy = eff$fit
ggplot(d,aes(x=age,y=accuracy))+
  geom_point()+
  geom_line(data=eff,color="red",size=2)

```

::: notes
vediamo graficamente che il modello predice bene i dati nuovi
ci permette di predire nuovi outcome compresi tra 0 e 1
e se facciamo lo stesso trick vediamo che il nuovo dataset, viola, presenta valori che stanno nel range di valori possibili per la nostra vd
:::

## ✅ More appropriate model 

```{r sup3}
#| echo: false

eff = data.frame(allEffects(fit,xlevels=list(age=seq(6,10,.1)))$"age")
eff$accuracy = eff$fit

d$pp_sim = simulate(fit)$sim_1
ggplot(d,aes(x=age,y=accuracy))+
  geom_point(aes(x=age,y=pp_sim),color="purple",size=3.5,alpha=.4)+
  geom_point()+
  geom_line(data=eff,color="red",size=2) +
  ylab("accuracy")
```

## ✅ More appropriate model 

```{r fitLogit}
#| echo: true
#| warning: false
fit = glm(accuracy ~ age, data=d, family=binomial(link="logit"), weights= rep(k, nrow(d)))
```

in this case, `link="logit"` makes sure that `y` spans from 0 and 1

# 3 Studying interactions

## Simulated dataset 2

independent variable: age in years (`years`)

dependent variable: mistakes in a TRUE/FALSE task (`accuracy`)

::: fragment
**adding a new main effect**

groups: normal kids (`group = 0`) 

kids with dyslexia (`group = 1`)
::: 

## Simulated dataset 2

```{r sim2int}
#| echo: false

set.seed(0)

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k

d = data.frame(
  age = age,
  age_c = age - mean(age),
  accuracy = accuracy,
  group = as.factor(group)
)

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point() +
  scale_x_continuous(limits = c(6, 10), breaks = seq(6, 10, 1))
```

## Identity link function

```{r fitLint-plot}
#| echo: false
#| warning: false

fitLint <- glm(accuracy ~ age * group, data = d)

eff <- data.frame(
  allEffects(
    fitLint,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point(alpha = .6) +
  geom_line(data = eff, aes(x = age, y = fit, group = group), size = 2)

```

## Identity link function

a **positive** interaction emerges

```{r fitLint}
#| echo: true
#| include: true
#| warning: true
fit = glm(accuracy ~ age*group, data=d)
summary(fit)
```

## Logit link function

```{r fitLogitint-plot}
#| echo: false
#| warning: false

fitLogitint = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"),
          weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitLogitint,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point(alpha = .6) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    size = 2
  )
```

## Logit link function

a **negative** interaction emerges

```{r fitLogitint}
#| echo: true
#| include: true
#| warning: false

fit = glm(accuracy ~ age*group, data=d, family=binomial(link="logit"), weights= rep(k, nrow(d)))
summary(fit)
```

::: notes
domanda (per alzata di mano): quale dei due modelli riflette ciò che ho simulato? o nessuno dei due?
riformula la domanda: in termini dell'esempio tipo all'aumentare dell'età,... 
e perché?
:::

## cosa ho effettivamente simulato

```{r datasim}
#| echo: true
#| code-fold: true

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k

d = data.frame(
  age = age,
  age_c = age - mean(age),
  accuracy = accuracy,
  group = as.factor(group)
)

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point() +
  scale_x_continuous(limits = c(6, 10), breaks = seq(6, 10, 1))
```

::: fragment
non ho simulato un'interazione, quindi ENTRAMBI i modelli trovano un'interazione che non c'è.
::: 

::: notes
sappiamo perché il modello lineare non funziona (da prima). ma perché non anche il modello di regressione logistica?
risposta: perché se tiro TUTTO a caso in un compito vero/falso di cui non si sa nulla del contenuto, allora l'accuratezza è del 50% non 0%! la regrssione logistica invece dice proprio questo: accuratezza dello 0%
pertanto, anche se la family è giusta (perché ci permette di predire sempre valori che spannano tra 0 e 1), dobbiamo usare un link diverso, che tenga conto di sta cosa. 
il link in questione si chiama e ve lo mostro nel modello
:::

## il vero modello in grado di fittare i dati

let's try out the **multiple alternative forced choice** (50% - bc of the true/false) probit link

```{r fitMint-plot}
#| echo: false
#| warning: false

fitM = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.probit(.m=2)), weights= rep(k, nrow(d)))

eff <- data.frame(
  allEffects(
    fitM,
    xlevels = list(age = seq(min(d$age), max(d$age), .05))
  )[["age:group"]]
)

ggplot(d, aes(x = age, y = accuracy, color = group)) +
  geom_point(alpha = .6) +
  geom_line(
    data = eff,
    aes(x = age, y = fit, group = group),
    size = 2
  )
```

## il vero modello in grado di fittare i dati: link="mafc.probit"

no interaction emerges !!!! as it should

```{r fitMint}
#| echo: true
#| warning: true

fit = glm(accuracy ~ age*group, data=d, family=binomial(link=mafc.probit(.m=2)), weights= rep(k, nrow(d)))
summary(fit)
```

# 4 Why interactions

## Identity link function

equal intervals on X correspond to equal intervals on Y

su x ed y metti i nomi delle variabili dell'esempio

```{r idlink}
#| echo: false
#| fig.align: "center" 

df_line <- data.frame(
  x = seq(-4.5, 4.5, length.out = 200)
)
df_line$y <- df_line$x


x_vals <- -4:4
y_vals <- -4:4

ggplot(df_line, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "blue",
    linewidth = 2
  ) +
  scale_x_continuous(
    limits = c(-4.5, 4.5),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(-4.5, 4.5),
    breaks = y_vals
  ) +
  
  # Etichette
  labs(
    x = "Linear component of the model",
    y = "Dependent variable"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    plot.title = element_text(face = "bold", color = "steelblue", size = 26),
    plot.subtitle = element_text(size = 18),
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14)
  )
```

## ✅ Log link function

equal intervals on X correspond to equal ratios (NOT equal intervals) on Y

```{r loglink}
#| echo: false
#| warning: false
#| fig.align: "center" 

df <- data.frame(
  x = seq(-2.2, 1.6, length.out = 300)
)
df$y <- exp(df$x)

x_vals <- seq(-1.5, 1.5, by = 0.5)
y_vals <- exp(x_vals)

ggplot(df, aes(x = x, y = y)) +
  geom_hline(
    yintercept = y_vals,
    color = "grey60",
    linewidth = 0.6
  ) +
  geom_vline(
    xintercept = x_vals,
    color = "red",
    linetype = "dashed",
    linewidth = 0.6
  ) +
  geom_line(
    color = "blue",
    linewidth = 2
  ) +
  annotate(
    "text",
    x = -2.25,
    y = y_vals,
    label = paste("y =", round(y_vals, 2)),
    hjust = 1,
    size = 4
  ) +
  annotate(
    "text",
    x = x_vals,
    y = -0.08,
    label = paste("x =", x_vals),
    vjust = 1,
    size = 4
  ) +
  scale_x_continuous(
    limits = c(-2.2, 1.6),
    breaks = x_vals
  ) +
  scale_y_continuous(
    limits = c(0, max(y_vals) + 0.8),
    breaks = y_vals
  ) +
  labs(
    x = "Linear component of the model",
    y = "Dependent variable (ie error rate)"
  ) +
  theme_minimal(base_size = 18) +
  theme(
    axis.title = element_text(size = 18),
    axis.text = element_text(size = 14)
  )
```


# Conclusions

## 

Building a model means that we want to find the processo generativo dei dati which, diversamente dal mondo delle simulazioni, we could never know for sure

to do that we must make important decisions

choosing the more appropriate **family of distributions** to make sure that the new values of the vd im predicting lie within the bounds

choosing the more appropriate **link function**: otherwise it's very likely you end up finding non linear effects (ie interactions) that are not there!

##

We're conducting a [systematic review](https://osf.io/tpjax/overview?view_only=7feccf54ff484fe093cf65579617b215) concerning how often the wrong link functions are used in psychological research + they lead to finding a significant interaction

so far, quite often

## Materials & Contact

All materials are available on GitHub at <a href="https://github.com/sitalaura/link-functions.git" target="_blank">sitalaura/link-functions</a>

Questions and feedbacks <a href="mailto: laura.sita@studenti.unipd.it" target="_blank">laura.sita\@studenti.unipd.it</a>

![](images/logo.png){fig-align="center" width="2.4cm"}

## Bibliography

<p style="font-size:70%; text-align:left; line-height:1.2;">
Domingue, B. W., Kanopka, K., Trejo, S., Rhemtulla, M., & Tucker-Drob, E. M. (2024). Ubiquitous bias and false discovery due to model misspecification in analysis of statistical interactions: The role of the outcome’s distribution and metric properties. *Psychological methods, 29*(6), 1164.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2;">
Hardwicke, T. E., Thibault, R. T., Clarke, B., Moodie, N., Crüwell, S., Schiavone, S. R., Handcock, S. A., Nghiem, K. A., Mody, F., Eerola, T., et al. (2024). Prevalence of transparent research practices in psychology: A cross-sectional study of empirical articles published in 2022. *Advances in Methods and Practices in Psychological Science, 7* (4), 25152459241283477.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2;">
Liddell, T. M., & Kruschke, J. K. (2018). Analyzing ordinal data with metric models: What could possibly go wrong?. *Journal of Experimental Social Psychology, 79*, 328-348.
</p>

<p style="font-size:70%; text-align:left; line-height:1.2;">
Micceri, T. (1989). The unicorn, the normal curve, and other improbable creatures. *Psychological bulletin, 105*(1), 156.
</p>

## Thank you

Special thanks to

# Supplementary materials

```{r sim2sup}
#| echo: false
set.seed(0)

k = 60
N = 400
age = runif(N,6,10)
eta = -5.5+age*0.9
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k
d = data.frame(age,accuracy)
```

## Posterior predictive check link="probit"

```{r sup1}
#| echo: true
#| warning: false
fit = glm(accuracy ~ age, data=d, family=binomial(link="probit"), weights= rep(k, nrow(d)))
```

```{r sup2}
#| echo: false

eff = data.frame(allEffects(fit,xlevels=list(age=seq(6,10,.1)))$"age")
eff$accuracy = eff$fit

d$pp_sim = simulate(fit)$sim_1
ggplot(d,aes(x=age,y=accuracy))+
  geom_point(aes(x=age,y=pp_sim),color="purple",size=3.5,alpha=.4)+
  geom_point()+
  geom_line(data=eff,color="red",size=2) +
  ylab("accuracy")
```

## Interaction with link="probit"

a **negative** interaction emerges

```{r sim2intsup}
#| echo: false
set.seed(0)

k = 50
N = 1000
group = rbinom(N,1,.5)
age = runif(N,6,10)
eta = -6+1*age-1*group
probs = mafc.probit(.m = 2)$linkinv(eta)
accuracy = rbinom(n = N, size = k, prob = probs) / k
d = data.frame(age=age-mean(age),accuracy,group=as.factor(group))
```

```{r sup4}
#| echo: true
fit = glm(accuracy ~ age*group, data=d, family=binomial(link="probit"), weights= rep(k, nrow(d)))
summary(fit)
```